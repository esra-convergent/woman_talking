{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MuseTalk Lip-Sync Service on Kaggle\n",
                "\n",
                "This notebook sets up MuseTalk for real-time lip-sync video generation.\n",
                "\n",
                "**Requirements:**\n",
                "- GPU enabled (Settings ‚Üí Accelerator ‚Üí GPU T4 x2)\n",
                "- Internet enabled (Settings ‚Üí Internet ‚Üí On)\n",
                "\n",
                "**What this does:**\n",
                "1. Installs MuseTalk\n",
                "2. Connects to LiveKit\n",
                "3. Listens for agent audio\n",
                "4. Generates lip-synced video\n",
                "5. Streams back to your React app"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU is available\n",
                "import torch\n",
                "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è NO GPU! Go to Settings ‚Üí Accelerator ‚Üí GPU T4 x2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q livekit livekit-api python-dotenv\n",
                "!pip install -q diffusers transformers accelerate omegaconf einops\n",
                "!pip install -q opencv-python librosa soundfile av pydub"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Clone MuseTalk Repository"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone MuseTalk\n",
                "!git clone https://github.com/TMElyralab/MuseTalk.git\n",
                "%cd MuseTalk\n",
                "\n",
                "# Download pretrained models\n",
                "!mkdir -p models/musetalk\n",
                "!wget -O models/musetalk/pytorch_model.bin https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalk/pytorch_model.bin\n",
                "\n",
                "# Download VAE\n",
                "!git clone https://huggingface.co/stabilityai/sd-vae-ft-mse models/sd-vae-ft-mse\n",
                "\n",
                "print(\"‚úÖ MuseTalk installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Upload Your Idle Video\n",
                "\n",
                "**Action needed:**\n",
                "1. Click 'Add Data' button (top right)\n",
                "2. Upload your `idle-avatar.mp4`\n",
                "3. Run the cell below to verify"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List uploaded files\n",
                "import os\n",
                "print(\"Files in /kaggle/input:\")\n",
                "for root, dirs, files in os.walk('/kaggle/input'):\n",
                "    for file in files:\n",
                "        print(f\"  {os.path.join(root, file)}\")\n",
                "\n",
                "# Set path to your idle video\n",
                "IDLE_VIDEO_PATH = '/kaggle/input/idle-avatar/idle-avatar.mp4'  # Adjust this path\n",
                "print(f\"\\nUsing video: {IDLE_VIDEO_PATH}\")\n",
                "print(f\"Exists: {os.path.exists(IDLE_VIDEO_PATH)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Test MuseTalk Standalone"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a test audio file (or upload your own)\n",
                "!pip install gTTS\n",
                "from gtts import gTTS\n",
                "\n",
                "# Generate test audio\n",
                "tts = gTTS(\"Hello, this is a test of the lip sync system.\", lang='en')\n",
                "tts.save('test_audio.mp3')\n",
                "\n",
                "# Convert to WAV\n",
                "!ffmpeg -i test_audio.mp3 -ar 16000 test_audio.wav -y\n",
                "print(\"‚úÖ Test audio created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run MuseTalk inference\n",
                "!python inference.py \\\n",
                "    --video_path {IDLE_VIDEO_PATH} \\\n",
                "    --audio_path test_audio.wav \\\n",
                "    --result_dir ./output\n",
                "\n",
                "print(\"\\n‚úÖ Video generated! Check ./output folder\")\n",
                "!ls -lh output/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Set Up LiveKit Connection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LiveKit credentials (get these from your .env.local file)\n",
                "LIVEKIT_URL = \"wss://emotion-test-k1t69r4e.livekit.cloud\"  # YOUR URL HERE\n",
                "LIVEKIT_API_KEY = \"YOUR_API_KEY_HERE\"  # FROM .env.local\n",
                "LIVEKIT_API_SECRET = \"YOUR_API_SECRET_HERE\"  # FROM .env.local\n",
                "\n",
                "print(\"LiveKit Config:\")\n",
                "print(f\"URL: {LIVEKIT_URL}\")\n",
                "print(f\"API Key: {LIVEKIT_API_KEY[:10]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Run MuseTalk LiveKit Service"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "import cv2\n",
                "import numpy as np\n",
                "from livekit import rtc, api\n",
                "from livekit.rtc import VideoFrame, AudioFrame\n",
                "import tempfile\n",
                "import os\n",
                "\n",
                "class MuseTalkService:\n",
                "    \"\"\"MuseTalk Lip-Sync Service for LiveKit\"\"\"\n",
                "    \n",
                "    def __init__(self, idle_video_path):\n",
                "        self.idle_video_path = idle_video_path\n",
                "        self.is_speaking = False\n",
                "        \n",
                "    async def generate_lipsync(self, audio_path):\n",
                "        \"\"\"Generate lip-synced video from audio\"\"\"\n",
                "        output_dir = tempfile.mkdtemp()\n",
                "        \n",
                "        # Run MuseTalk\n",
                "        cmd = f\"\"\"python inference.py \\\n",
                "            --video_path {self.idle_video_path} \\\n",
                "            --audio_path {audio_path} \\\n",
                "            --result_dir {output_dir}\n",
                "        \"\"\"\n",
                "        os.system(cmd)\n",
                "        \n",
                "        # Find generated video\n",
                "        videos = [f for f in os.listdir(output_dir) if f.endswith('.mp4')]\n",
                "        if videos:\n",
                "            return os.path.join(output_dir, videos[0])\n",
                "        return None\n",
                "    \n",
                "    async def stream_video(self, video_path, video_source):\n",
                "        \"\"\"Stream video frames to LiveKit\"\"\"\n",
                "        cap = cv2.VideoCapture(video_path)\n",
                "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "        frame_duration = 1.0 / fps\n",
                "        \n",
                "        while cap.isOpened():\n",
                "            ret, frame = cap.read()\n",
                "            if not ret:\n",
                "                break\n",
                "                \n",
                "            # Convert BGR to RGB\n",
                "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "            \n",
                "            # Create VideoFrame\n",
                "            video_frame = VideoFrame(\n",
                "                width=frame_rgb.shape[1],\n",
                "                height=frame_rgb.shape[0],\n",
                "                type=rtc.VideoBufferType.RGBA,\n",
                "                data=frame_rgb.tobytes()\n",
                "            )\n",
                "            \n",
                "            # Send to LiveKit\n",
                "            video_source.capture_frame(video_frame)\n",
                "            \n",
                "            await asyncio.sleep(frame_duration)\n",
                "        \n",
                "        cap.release()\n",
                "\n",
                "print(\"‚úÖ MuseTalk service ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main LiveKit connection\n",
                "async def run_musetalk_agent():\n",
                "    \"\"\"Connect to LiveKit and handle lip-sync\"\"\"\n",
                "    \n",
                "    # Generate access token\n",
                "    token = api.AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET)\n",
                "    token.with_identity(\"musetalk-service\")\n",
                "    token.with_name(\"MuseTalk Video Generator\")\n",
                "    token.with_grants(api.VideoGrants(\n",
                "        room_join=True,\n",
                "        room=\"voice-chat-test\",  # Adjust room name\n",
                "        can_publish=True,\n",
                "        can_subscribe=True,\n",
                "    ))\n",
                "    \n",
                "    jwt = token.to_jwt()\n",
                "    \n",
                "    # Connect to room\n",
                "    room = rtc.Room()\n",
                "    \n",
                "    @room.on(\"track_subscribed\")\n",
                "    def on_track_subscribed(track, publication, participant):\n",
                "        print(f\"Track subscribed: {track.kind} from {participant.identity}\")\n",
                "        \n",
                "        # Listen for agent audio\n",
                "        if track.kind == rtc.TrackKind.KIND_AUDIO and \"agent\" in participant.identity:\n",
                "            print(\"üì¢ Detected agent audio! Generating lip-sync...\")\n",
                "            # TODO: Capture audio, generate video, stream back\n",
                "    \n",
                "    # Connect\n",
                "    print(f\"Connecting to {LIVEKIT_URL}...\")\n",
                "    await room.connect(LIVEKIT_URL, jwt)\n",
                "    print(f\"‚úÖ Connected to room: {room.name}\")\n",
                "    \n",
                "    # Publish video track\n",
                "    video_source = rtc.VideoSource(1280, 720)\n",
                "    video_track = rtc.LocalVideoTrack.create_video_track(\"musetalk-video\", video_source)\n",
                "    await room.local_participant.publish_track(video_track)\n",
                "    print(\"‚úÖ Video track published\")\n",
                "    \n",
                "    # Stream idle video\n",
                "    musetalk = MuseTalkService(IDLE_VIDEO_PATH)\n",
                "    await musetalk.stream_video(IDLE_VIDEO_PATH, video_source)\n",
                "    \n",
                "# Run the agent\n",
                "# await run_musetalk_agent()  # Uncomment when ready to connect"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Test Connection\n",
                "\n",
                "Run this cell to start the MuseTalk service and connect to LiveKit:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start the service\n",
                "await run_musetalk_agent()\n",
                "\n",
                "# This will run until you stop the cell\n",
                "# You should see the video stream in your React app!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}